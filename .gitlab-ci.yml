# Configuration borrowed from https://gitlab.cern.ch/db/swan-spark-notebooks
before_script:
  - mkdir -p ~/.ssh
  - echo -e "Host *\n\tStrictHostKeyChecking no\n\n" > ~/.ssh/config
  - eval $(ssh-agent -s)
  - echo "$SSH_DEPLOY_KEY" | tr -d '\r' | ssh-add - > /dev/null
  - mkdir -p ~/.ssh && touch ~/.ssh/known_hosts
  - echo "$SSH_KNOWN_HOSTS" >> ~/.ssh/known_hosts
  - git submodule sync --recursive
  - git submodule update --init --recursive

stages:
  - image-build
  - submit-prod-notebook
  - submit-qa-notebook
  - submit-test-notebook

variables:
  HADOOP_CONFEXT_QA_BRANCH: "testing"
  KRB5CCNAME: "/tmp/krb5cc"

### COMMON ###

# Deploy docker image to gitlab registry
build-docker-image:
  stage: image-build
  only:
    - /^docker-.*$/
  tags:
    - docker-image-build
  script:
    - echo "Build docker image..."
  variables:
    DOCKER_FILE: Dockerfile
    TO: ${CI_REGISTRY_IMAGE}:latest

# Template for the job
.job_template: &job_template
  tags:
    - cvmfs
  image:
    name: ${CI_REGISTRY_IMAGE}:latest
    entrypoint: ["/bin/sh", "-c"]
  
### K8S ###

docker-k8s-notebook:
  <<: *job_template
  image:
    name: gitlab-registry.cern.ch/db/spark-service/docker-registry/spark:v2.4.4-hadoop2
    entrypoint: ["/bin/sh", "-c"]
  stage: submit-test-notebook
  script:
    # set KUBECONFIG
    - cp ./swan-spark-notebooks/k8s-example/kubeconfig /tmp/kubeconfig
    - sed -i -e "s/K8S_SSL_CERTIFICATE/$K8S_SSL_CERTIFICATE/g" /tmp/kubeconfig; sed -i -e "s,K8S_MASTER,$K8S_MASTER,g" /tmp/kubeconfig; sed -i -e "s/K8S_TOKEN/$K8S_TOKEN/g" /tmp/kubeconfig
    - export KUBECONFIG=/tmp/kubeconfig
    # submit notebook
    - python ./swan-spark-notebooks/k8s-example/submit_k8s_dockerfile_ipynb.py --spark-image gitlab-registry.cern.ch/db/spark-service/docker-registry/spark:v2.4.4-hadoop2 --ipynb ./swan-spark-notebooks/k8s-example/spark-pi.ipynb --appid prod-docker-image-notebook-$RANDOM --hadoop-confext /cvmfs/sft.cern.ch/lcg/etc/hadoop-confext
