{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell if you do not have coffea installed (e.g. on SWAN with LCG 96Python3 stack)\n",
    "!pip install --user --upgrade coffea\n",
    "\n",
    "# spark.jars.packages doesnt work with Spark 2.4 with kubernetes\n",
    "!wget -N https://repo1.maven.org/maven2/edu/vanderbilt/accre/laurelin/1.0.0/laurelin-1.0.0.jar\n",
    "!wget -N https://repo1.maven.org/maven2/org/apache/logging/log4j/log4j-api/2.11.2/log4j-api-2.11.2.jar\n",
    "!wget -N https://repo1.maven.org/maven2/org/apache/logging/log4j/log4j-core/2.11.2/log4j-core-2.11.2.jar\n",
    "!wget -N https://repo1.maven.org/maven2/org/lz4/lz4-java/1.5.1/lz4-java-1.5.1.jar\n",
    "!wget -N https://repo1.maven.org/maven2/org/tukaani/xz/1.2/xz-1.2.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell before establishing spark connection <<<<< IMPORTANT\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONPATH'] = os.environ['PYTHONPATH'] + ':' + '/usr/local/lib/python3.6/site-packages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import pyspark.sql\n",
    "from pyarrow.compat import guid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coffea import hist\n",
    "from coffea.analysis_objects import JaggedCandidateArray\n",
    "import coffea.processor as processor\n",
    "from coffea.processor.spark.detail import _spark_initialize, _spark_stop\n",
    "from coffea.processor.spark.spark_executor import spark_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numba as nb\n",
    "import awkward as ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters to be changed\n",
    "partitionsize = 20000\n",
    "# parameters to be changed\n",
    "thread_workers = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileset = {\n",
    "    'massT': { 'files': ['root://eospublic.cern.ch//eos/root-eos/benchmark/Run2012B_SingleMu.root'],\n",
    "             'treename': 'Events'\n",
    "            }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "available_laurelin_version = [(\"edu.vanderbilt.accre:laurelin:1.0.0\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.njit()\n",
    "def trilepton_selection(ee_starts, ee_stops, ee_arg0s, ee_arg1s,\n",
    "                        mm_starts, mm_stops, mm_arg0s, mm_arg1s,\n",
    "                        e_starts, e_stops, e_px, e_py, e_pz, e_E,\n",
    "                        mu_starts, mu_stops, mu_px, mu_py, mu_pz, mu_E):\n",
    "    # as input we receive the indices of the best os/sf pairs\n",
    "    # here we need to figure out if there's a contention between ee and mm\n",
    "    # arbitrate and then select the appropriate third, highest pT lepton\n",
    "    # we will return the mask that selects the lepton\n",
    "    pole = 91.18\n",
    "    e_out = np.zeros(e_px.size, nb.boolean)\n",
    "    mu_out = np.zeros(mu_px.size, nb.boolean)\n",
    "    ee_out = np.zeros(ee_arg0s.size, nb.boolean)\n",
    "    mm_out = np.zeros(mm_arg0s.size, nb.boolean)\n",
    "\n",
    "    for i_evt in range(ee_starts.size):\n",
    "        best_ll = []\n",
    "        best_ll_index = []\n",
    "        n_lls = 0\n",
    "        ll_type = 0\n",
    "        for i_ee in range(ee_starts[i_evt], ee_stops[i_evt]):\n",
    "            best_ll.append((e_starts[i_evt] + ee_arg0s[i_ee], e_starts[i_evt] +  ee_arg1s[i_ee]))\n",
    "            best_ll_index.append(i_ee)\n",
    "            n_lls += 1\n",
    "            ll_type += 0\n",
    "        for i_mm in range(mm_starts[i_evt], mm_stops[i_evt]):\n",
    "            best_ll.append((mu_starts[i_evt] + mm_arg0s[i_mm], mu_starts[i_evt] + mm_arg1s[i_mm]))\n",
    "            best_ll_index.append(i_mm)\n",
    "            n_lls += 1\n",
    "            ll_type += 1        \n",
    "\n",
    "        ee_mass = 0.0\n",
    "        mm_mass = 0.0\n",
    "        if n_lls == 0:\n",
    "            continue\n",
    "        elif n_lls == 1:\n",
    "            pass\n",
    "        else:\n",
    "            ee0, ee1 = best_ll[0]\n",
    "            ee_mass = np.sqrt((e_E[ee0] + e_E[ee1])**2 - \n",
    "                              ((e_px[ee0] + e_px[ee1])**2 +\n",
    "                               (e_py[ee0] + e_py[ee1])**2 +\n",
    "                               (e_pz[ee0] + e_pz[ee1])**2))\n",
    "            mm0, mm1 = best_ll[1]\n",
    "            mm_mass = np.sqrt((mu_E[mm0] + mu_E[mm1])**2 - \n",
    "                              ((mu_px[mm0] + mu_px[mm1])**2 + \n",
    "                               (mu_py[mm0] + mu_py[mm1])**2 + \n",
    "                               (mu_pz[mm0] + mu_pz[mm1])**2))\n",
    "            ll_type = int(np.abs(ee_mass - pole) >= np.abs(mm_mass - pole))\n",
    "\n",
    "        ll0, ll1 = best_ll[0] if n_lls == 1 else best_ll[ll_type]\n",
    "\n",
    "        if ll_type == 0:\n",
    "            ee_out[best_ll_index[0]] = True\n",
    "        else:\n",
    "            idx = n_lls - 1\n",
    "            mm_out[best_ll_index[idx]] = True\n",
    "\n",
    "        best_third_type = -1 \n",
    "        best_third_lepton = -1 \n",
    "        best_third_lepton_pt = 0.\n",
    "        for i_e in range(e_starts[i_evt], e_stops[i_evt]):\n",
    "            if ll_type == 0:\n",
    "                if i_e == ll0 or i_e == ll1:\n",
    "                    continue\n",
    "            if best_third_type is None:\n",
    "                best_third_type = 0\n",
    "                best_third_lepton = i_e\n",
    "                best_third_lepton_pt = np.sqrt(e_px[i_e]**2 + e_py[i_e]**2)\n",
    "            else:\n",
    "                i_e_pt = np.sqrt(e_px[i_e]**2 + e_py[i_e]**2)\n",
    "                if i_e_pt > best_third_lepton_pt:\n",
    "                    best_third_type = 0\n",
    "                    best_third_lepton = i_e\n",
    "                    best_third_lepton_pt = i_e_pt\n",
    "\n",
    "        for i_mu in range(mu_starts[i_evt], mu_stops[i_evt]):\n",
    "            if ll_type == 1:\n",
    "                if i_mu == ll0 or i_mu == ll1:\n",
    "                    continue\n",
    "            if best_third_type is None:\n",
    "                best_third_type = 1\n",
    "                best_third_lepton = i_mu\n",
    "                best_third_lepton_pt = np.sqrt(mu_px[i_mu]**2 + mu_py[i_mu]**2)\n",
    "            else:\n",
    "                i_mu_pt = np.sqrt(mu_px[i_mu]**2 + mu_py[i_mu]**2)\n",
    "                if i_mu_pt > best_third_lepton_pt:\n",
    "                    best_third_type = 1\n",
    "                    best_third_lepton = i_mu\n",
    "                    best_third_lepton_pt = i_mu_pt\n",
    "        \n",
    "        if best_third_type > -1:\n",
    "            if best_third_type == 0:\n",
    "                e_out[best_third_lepton] = True\n",
    "            if best_third_type == 1:\n",
    "                mu_out[best_third_lepton] = True\n",
    "        \n",
    "        \n",
    "    return e_out, mu_out, ee_out, mm_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This program plots the transverse mass of MET and a third lepton, where the third lepton is associated with a lepton pair\n",
    "that has the same flavor, opposite charge, and closest mass to 91.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class DibosonProcessor(processor.ProcessorABC):\n",
    "    def __init__(self):\n",
    "        self._columns = ['MET_pt', 'nMuon', 'Muon_pt', 'Muon_eta', 'Muon_phi', 'Muon_mass', 'Muon_charge', \n",
    "                         'nElectron', 'Electron_pt', 'Electron_eta', 'Electron_phi', 'Electron_mass', 'Electron_charge']\n",
    "        dataset_axis = hist.Cat(\"dataset\", \"MET and Third Lepton\")\n",
    "        muon_axis = hist.Bin(\"massT\", \"Transverse Mass\", 50, 15, 250)\n",
    "        self._accumulator = processor.dict_accumulator({\n",
    "            'massT': hist.Hist(\"Counts\", dataset_axis, muon_axis),\n",
    "            'cutflow': processor.defaultdict_accumulator(int)\n",
    "        })\n",
    "\n",
    "    @property\n",
    "    def columns(self):\n",
    "        return self._columns\n",
    "    \n",
    "    @property\n",
    "    def accumulator(self):\n",
    "        return self._accumulator\n",
    "    \n",
    "    def process(self, df):\n",
    "        output = self.accumulator.identity()\n",
    "        dataset = df[\"dataset\"]\n",
    "        muons = JaggedCandidateArray.candidatesfromcounts(\n",
    "                    df['nMuon'],\n",
    "                    pt=df['Muon_pt'].content,\n",
    "                    eta=df['Muon_eta'].content,\n",
    "                    phi=df['Muon_phi'].content,\n",
    "                    mass=df['Muon_mass'].content,\n",
    "                    charge=df['Muon_charge'].content\n",
    "                    )\n",
    "        electrons = JaggedCandidateArray.candidatesfromcounts(\n",
    "                    df['nElectron'],\n",
    "                    pt=df['Electron_pt'].content,\n",
    "                    eta=df['Electron_eta'].content,\n",
    "                    phi=df['Electron_phi'].content,\n",
    "                    mass=df['Electron_mass'].content,\n",
    "                    charge=df['Electron_charge'].content\n",
    "                    )\n",
    "        # a few reasonable muon and electron selection cuts\n",
    "        muons = muons[(muons.pt > 10) & (np.abs(muons.eta) < 2.4)]\n",
    "        electrons = electrons[(electrons.pt > 10) & (np.abs(electrons.eta) < 2.5)]\n",
    "        trileptons = (muons.counts + electrons.counts) >= 3\n",
    "        muons = muons[trileptons].compact()\n",
    "        electrons = electrons[trileptons].compact()        \n",
    "        diele = electrons.distincts()\n",
    "        dimu = muons.distincts()\n",
    "        # same for dileptons\n",
    "        diele = diele[(diele.i0.charge * diele.i1.charge < 0) & (diele.mass > 50) & (diele.mass < 160)]\n",
    "        dimu = dimu[(dimu.i0.charge * dimu.i1.charge < 0) & (dimu.mass > 50) & (dimu.mass < 160)]\n",
    "        #get the dileptons closest to the z-pole\n",
    "        best_diele = np.abs(diele.mass - 91.18).argmin()\n",
    "        best_dimu = np.abs(dimu.mass - 91.18).argmin()\n",
    "        diele_args = electrons.argdistincts()[best_diele].compact()\n",
    "        dimu_args = muons.argdistincts()[best_dimu].compact()\n",
    "        # select the third lepton with highest pT that's not in the z-candidate\n",
    "        # it returns a mask that selects the appropriate dilepton and third lepton\n",
    "        # the mask is already exclusive across lepton types\n",
    "        e_mask_contents, mu_mask_contents, ee_mask_contents, mm_mask_contents = \\\n",
    "            trilepton_selection(diele_args.starts, diele_args.stops, diele_args.i0.content, diele_args.i1.content,\n",
    "                                dimu_args.starts, dimu_args.stops, dimu_args.i0.content, dimu_args.i1.content,\n",
    "                                electrons.starts, electrons.stops, \n",
    "                                electrons.p4.x.content, electrons.p4.y.content, \n",
    "                                electrons.p4.z.content, electrons.p4.energy.content,\n",
    "                                muons.starts, muons.stops, \n",
    "                                muons.p4.x.content, muons.p4.y.content, \n",
    "                                muons.p4.z.content, muons.p4.energy.content)\n",
    "        e_mask = ak.JaggedArray.fromoffsets(electrons.offsets,e_mask_contents)\n",
    "        mu_mask = ak.JaggedArray.fromoffsets(muons.offsets,mu_mask_contents)\n",
    "        ee_mask = ak.JaggedArray.fromoffsets(diele_args.offsets,ee_mask_contents)\n",
    "        mm_mask = ak.JaggedArray.fromoffsets(dimu_args.offsets,mm_mask_contents)\n",
    "        third_es = electrons[e_mask]\n",
    "        third_ms = muons[mu_mask]\n",
    "        \n",
    "        #print(ee_mask)\n",
    "        #print(mm_mask)\n",
    "        #print()\n",
    "        #print(e_mask)\n",
    "        #print(mu_mask)\n",
    "        \n",
    "        MET_pt = df['MET_pt'][trileptons]\n",
    "        MET_phi = df['MET_phi'][trileptons]    \n",
    "        MET_tab = ak.JaggedArray.fromcounts(np.ones_like(MET_pt, dtype=np.int), ak.Table({'phi': MET_phi, 'pt': MET_pt}))\n",
    "        met_plus_e = MET_tab.cross(third_es)\n",
    "        met_plus_mu = MET_tab.cross(third_ms)\n",
    "        dphi_met_e = (met_plus_e.i0.phi - met_plus_e.i1.p4.phi + math.pi) % (2*math.pi) - math.pi\n",
    "        dphi_met_mu = (met_plus_mu.i0.phi - met_plus_mu.i1.p4.phi + math.pi) % (2*math.pi) - math.pi\n",
    "        mt_e = np.sqrt(2.0*met_plus_e.i0.pt*met_plus_e.i1.p4.pt*(1.0-np.cos(dphi_met_e)))\n",
    "        mt_mu = np.sqrt(2.0*met_plus_mu.i0.pt*met_plus_mu.i1.p4.pt*(1.0-np.cos(dphi_met_mu)))\n",
    "        output['massT'].fill(dataset=dataset, massT=mt_e.flatten())\n",
    "        output['massT'].fill(dataset=dataset, massT=mt_mu.flatten())\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def postprocess(self, accumulator):\n",
    "        return accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def coffea_laurelin_adl_example8(laurelin_version, fileset):\n",
    "    spark_config = pyspark.sql.SparkSession.builder \\\n",
    "        .appName('spark-executor-test-%s' % guid()) \\\n",
    "        .master('local[*]') \\\n",
    "        .config('spark.driver.memory', '4g') \\\n",
    "        .config('spark.executor.memory', '6g') \\\n",
    "        .config('spark.sql.execution.arrow.enabled','true') \\\n",
    "        .config('spark.sql.execution.arrow.maxRecordsPerBatch', 20000)\\\n",
    "        .config('spark.driver.extraClassPath', './laurelin-1.0.0.jar:./lz4-java-1.5.1.jar:./log4j-core-2.11.2.jar:./log4j-api-2.11.2.jar:./xz-1.2.jar')\\\n",
    "        .config('spark.kubernetes.container.image.pullPolicy', 'true')\\\n",
    "        .config('spark.kubernetes.container.image', 'gitlab-registry.cern.ch/db/spark-service/docker-registry/swan:laurelin')\\\n",
    "        .config('spark.kubernetes.memoryOverheadFactor', '0.1')\n",
    "\n",
    "\n",
    "    spark = _spark_initialize(config=spark_config, log_level='WARN', \n",
    "                          spark_progress=False, laurelin_version='1.0.0')\n",
    "    \n",
    "    output = processor.run_spark_job(fileset,\n",
    "                                     DibosonProcessor(),\n",
    "                                     spark_executor, \n",
    "                                     spark=spark,\n",
    "                                     partitionsize=partitionsize,\n",
    "                                     thread_workers=thread_workers,\n",
    "                                     executor_args={'file_type': 'edu.vanderbilt.accre.laurelin.Root', 'cache': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@pytest.mark.skip(reason=\"Dataset is too big! no way of currently testing this...\")\n",
    "@pytest.mark.benchmark(group=\"coffea-laurelin-adl-example8\")\n",
    "@pytest.mark.parametrize(\"laurelin_version\", available_laurelin_version)\n",
    "@pytest.mark.parametrize(\"root_file\", fileset)\n",
    "def test_coffea_laurelin_adl_example8(benchmark, laurelin_version, root_file):\n",
    "    benchmark(coffea_laurelin_adl_example8, laurelin_version, fileset)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
