{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell if you do not have coffea installed (e.g. on SWAN with LCG 96Python3 stack)\n",
    "# (for .py version -> next line should be commented since they are converted to ipybn via jupytext)\n",
    "!pip install --user --upgrade coffea\n",
    "# Preparation for testing\n",
    "!pip install --user --upgrade ipytest\n",
    "!pip install --user --upgrade pytest-benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# spark.jars.packages doesnt work with Spark 2.4 with kubernetes\n",
    "!wget -N https://repo1.maven.org/maven2/edu/vanderbilt/accre/laurelin/1.0.0/laurelin-1.0.0.jar\n",
    "!wget -N https://repo1.maven.org/maven2/org/apache/logging/log4j/log4j-api/2.11.2/log4j-api-2.11.2.jar\n",
    "!wget -N https://repo1.maven.org/maven2/org/apache/logging/log4j/log4j-core/2.11.2/log4j-core-2.11.2.jar\n",
    "!wget -N https://repo1.maven.org/maven2/org/lz4/lz4-java/1.5.1/lz4-java-1.5.1.jar\n",
    "!wget -N https://repo1.maven.org/maven2/org/tukaani/xz/1.2/xz-1.2.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if hasattr(__builtins__,'__IPYTHON__'):\n",
    "    import os\n",
    "    import ipytest\n",
    "    ipytest.config(rewrite_asserts=True, magics=True)\n",
    "    __file__ = 'test_coffea_dask_adl_example1.ipynb'\n",
    "    # Run this cell before establishing spark connection <<<<< IMPORTANT\n",
    "    os.environ['PYTHONPATH'] = os.environ['PYTHONPATH'] + ':' + '/usr/local/lib/python3.6/site-packages'\n",
    "    os.environ['PATH'] = os.environ['PATH'] + ':' + '/eos/user/o/oshadura/.local/bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "import pytest\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coffea import hist\n",
    "from coffea.analysis_objects import JaggedCandidateArray\n",
    "import coffea.processor as processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'PYSPARK_COFFEABENCH' in os.environ:\n",
    "    import pyspark.sql\n",
    "    from pyarrow.compat import guid\n",
    "    from coffea.processor.spark.detail import _spark_initialize, _spark_stop\n",
    "    from coffea.processor.spark.spark_executor import spark_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_laurelin_version = [(\"edu.vanderbilt.accre:laurelin:1.0.1-SNAPSHOT\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'DASK_COFFEABENCH' in os.environ:\n",
    "    from dask.distributed import Client, LocalCluster\n",
    "    from dask_jobqueue import HTCondorCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "fileset = {\n",
    "    'Jets': { 'files': ['root://eospublic.cern.ch//eos/root-eos/benchmark/Run2012B_SingleMu.root'],\n",
    "             'treename': 'Events'\n",
    "            }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This program plots an event-level variable (in this case, MET, but switching it is as easy as a dict-key change). It also demonstrates an easy use of the book-keeping cutflow tool, to keep track of the number of events processed.\n",
    "# The processor class bundles our data analysis together while giving us some helpful tools.  It also leaves looping and chunks to the framework instead of us.\n",
    "class METProcessor(processor.ProcessorABC):\n",
    "    def __init__(self):\n",
    "        # Bins and categories for the histogram are defined here. For format, see https://coffeateam.github.io/coffea/stubs/coffea.hist.hist_tools.Hist.html && https://coffeateam.github.io/coffea/stubs/coffea.hist.hist_tools.Bin.html\n",
    "        self._columns = ['MET_pt']\n",
    "        dataset_axis = hist.Cat(\"dataset\", \"\")\n",
    "        MET_axis = hist.Bin(\"MET\", \"MET [GeV]\", 50, 0, 100)\n",
    "        # The accumulator keeps our data chunks together for histogramming. It also gives us cutflow, which can be used to keep track of data.\n",
    "        self._accumulator = processor.dict_accumulator({\n",
    "            'MET': hist.Hist(\"Counts\", dataset_axis, MET_axis),\n",
    "            'cutflow': processor.defaultdict_accumulator(int)\n",
    "        })\n",
    "\n",
    "    @property\n",
    "    def accumulator(self):\n",
    "        return self._accumulator\n",
    "\n",
    "    @property\n",
    "    def columns(self):\n",
    "        return self._columns\n",
    "\n",
    "    def process(self, df):\n",
    "        output = self.accumulator.identity()\n",
    "        # This is where we do our actual analysis. The df has dict keys equivalent to the TTree's.\n",
    "        dataset = df['dataset']\n",
    "        MET = df['MET_pt']\n",
    "        # We can define a new key for cutflow (in this case 'all events'). Then we can put values into it. We need += because it's per-chunk (demonstrated below)\n",
    "        output['cutflow']['all events'] += MET.size\n",
    "        output['cutflow']['number of chunks'] += 1\n",
    "        # This fills our histogram once our data is collected. Always use .flatten() to make sure the array is reduced. The output key will be as defined in __init__ for self._accumulator; the hist key ('MET=') will be defined in the bin.\n",
    "        output['MET'].fill(dataset=dataset, MET=MET.flatten())\n",
    "        return output\n",
    "\n",
    "    def postprocess(self, accumulator):\n",
    "        return accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def coffea_dask_adlexample1(n_cores=2):\n",
    "    # Dask settings (two different cases)\n",
    "    client = Client(\"t3.unl.edu:8786\")\n",
    "    #cluster = HTCondorCluster(cores=n_cores, memory=\"2GB\",disk=\"1GB\",dashboard_address=9998)\n",
    "    #cluster.scale(jobs=5)\n",
    "    #client = Client(cluster)\n",
    "    cachestrategy = 'dask-worker'\n",
    "    exe_args = {\n",
    "        'client': client,\n",
    "        'nano': True,\n",
    "        'cachestrategy': cachestrategy,\n",
    "        'savemetrics': True,\n",
    "        'worker_affinity': True if cachestrategy is not None else False,\n",
    "    }\n",
    "    output = processor.run_uproot_job(fileset,\n",
    "                                treename = 'Events',\n",
    "                                processor_instance = METProcessor(),\n",
    "                                executor = processor.dask_executor,\n",
    "                                executor_args = exe_args\n",
    "                                )\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "if 'DASK_COFFEABENCH' in os.environ:\n",
    "    @pytest.mark.benchmark(group=\"coffea-dask-adl-example1\")\n",
    "    def test_dask_adlexample1(benchmark):\n",
    "        benchmark(coffea_dask_adlexample1, n_workers, partition_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def coffea_laurelin_adlexample1(laurelin_version, n_workers, partition_size):\n",
    "    spark_config = pyspark.sql.SparkSession.builder \\\n",
    "        .appName('spark-executor-test-%s' % guid()) \\\n",
    "        .master('local[*]') \\\n",
    "        .config('spark.driver.memory', '4g') \\\n",
    "        .config('spark.executor.memory', '6g') \\\n",
    "        .config('spark.sql.execution.arrow.enabled','true') \\\n",
    "        .config('spark.sql.execution.arrow.maxRecordsPerBatch', partition_size)\\\n",
    "        .config('spark.kubernetes.container.image.pullPolicy', 'true')\\\n",
    "        .config('spark.kubernetes.container.image', 'gitlab-registry.cern.ch/db/spark-service/docker-registry/swan:laurelin')\\\n",
    "        .config('spark.kubernetes.memoryOverheadFactor', '0.1')\n",
    "\n",
    "    spark = _spark_initialize(config=spark_config, log_level='WARN',\n",
    "                          spark_progress=False, laurelin_version=laurelin_version)\n",
    "\n",
    "    output = processor.run_spark_job(fileset, \n",
    "                                     METProcessor(), \n",
    "                                     spark_executor,\n",
    "                                     spark=spark,\n",
    "                                     partitionsize=partition_size,\n",
    "                                     thread_workers=n_workers,\n",
    "                                     executor_args={'file_type': 'edu.vanderbilt.accre.laurelin.Root', 'cache': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'PYSPARK_COFFEABENCH' in os.environ:\n",
    "    @pytest.mark.benchmark(group=\"coffea-laurelin-adl-example1\")\n",
    "    @pytest.mark.parametrize(\"laurelin_version\", available_laurelin_version)\n",
    "    @pytest.mark.parametrize(\"n_workers\", range(1,psutil.cpu_count(logical=False)))\n",
    "    @pytest.mark.parametrize(\"partition_size\", range(100000,200000,100000))\n",
    "    def test_laurelin_adlexample1(benchmark, laurelin_version, n_workers, partition_size):\n",
    "        benchmark(coffea_laurelin_adlexample1, available_laurelin_version, n_workers, partition_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def coffea_uproot_adlexample1(n_workers, chunk_size, maxchunk_size):\n",
    "    output = processor.run_uproot_job(fileset,\n",
    "                                      treename = 'Events',\n",
    "                                      processor_instance = METProcessor(),\n",
    "                                      executor = processor.futures_executor,\n",
    "                                      chunksize = chunk_size,\n",
    "                                      maxchunks = maxchunk_size,\n",
    "                                      executor_args = {'workers': n_workers}                               \n",
    "    )\n",
    "    return output  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if 'UPROOT_COFFEABENCH' in os.environ:\n",
    "    @pytest.mark.benchmark(group=\"coffea-uproot-adl-example1\")\n",
    "    @pytest.mark.parametrize(\"n_workers\", range(1,psutil.cpu_count(logical=False)))\n",
    "    @pytest.mark.parametrize(\"chunk_size\", range(200000,600000,200000))\n",
    "    @pytest.mark.parametrize(\"maxchunk_size\", range(300000,700000,200000))\n",
    "    def test_uproot_adlexample1(benchmark, n_workers, chunk_size, maxchunk_size):\n",
    "        benchmark(coffea_uproot_adlexample1, n_workers, chunk_size, maxchunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(__builtins__,'__IPYTHON__'):\n",
    "    ipytest.run('-qq')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
