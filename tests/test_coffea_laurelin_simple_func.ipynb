{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell if you do not have coffea installed (e.g. on SWAN with LCG 96Python3 stack)\n",
    "# (for .py version -> next line should be commented since they are converted to ipybn via jupytext)\n",
    "!pip install --user --upgrade coffea\n",
    "# Preparation for testing\n",
    "!pip install --user --upgrade ipytest\n",
    "!pip install --user --upgrade pytest-benchmark\n",
    "!pip install --user --upgrade pytest-csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.jars.packages doesnt work with Spark 2.4 with kubernetes\n",
    "!wget -N https://repo1.maven.org/maven2/edu/vanderbilt/accre/laurelin/1.0.0/laurelin-1.0.0.jar\n",
    "!wget -N https://repo1.maven.org/maven2/org/apache/logging/log4j/log4j-api/2.11.2/log4j-api-2.11.2.jar\n",
    "!wget -N https://repo1.maven.org/maven2/org/apache/logging/log4j/log4j-core/2.11.2/log4j-core-2.11.2.jar\n",
    "!wget -N https://repo1.maven.org/maven2/org/lz4/lz4-java/1.5.1/lz4-java-1.5.1.jar\n",
    "!wget -N https://repo1.maven.org/maven2/org/tukaani/xz/1.2/xz-1.2.jar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment this if you want to test Dask:\n",
    "%env DASK_COFFEABENCH=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment this if you want to test Spark:\n",
    "%env PYSPARK_COFFEABENCH=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment this if you want to test uproot:\n",
    "%env UPROOT_COFFEABENCH=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(__builtins__,'__IPYTHON__'):\n",
    "    import os\n",
    "    import ipytest\n",
    "    ipytest.config(rewrite_asserts=True, magics=True)\n",
    "    __file__ = 'test_coffea_laurelin_simple_func.ipynb'\n",
    "    # Run this cell before establishing spark connection <<<<< IMPORTANT\n",
    "    os.environ['PYTHONPATH'] = os.environ['PYTHONPATH'] + ':' + '/usr/local/lib/python3.6/site-packages'\n",
    "    os.environ['PATH'] = os.environ['PATH'] + ':' + '/eos/user/o/oshadura/.local/bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'PYSPARK_COFFEABENCH' in os.environ:\n",
    "    import pyspark.sql\n",
    "    from pyarrow.compat import guid\n",
    "    from pyspark.sql.types import BinaryType, StringType, StructType, StructField\n",
    "    import pyspark.sql.functions as fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jinja2 import Environment, PackageLoader, select_autoescape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coffea import hist\n",
    "from coffea.analysis_objects import JaggedCandidateArray\n",
    "import coffea.processor as processor\n",
    "from coffea.processor.test_items import NanoTestProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'PYSPARK_COFFEABENCH' in os.environ:\n",
    "    from coffea.processor.spark.detail import (_spark_initialize,\n",
    "                                           _spark_make_dfs,\n",
    "                                           _spark_stop)\n",
    "    from coffea.processor.spark.spark_executor import spark_executor\n",
    "    from coffea.processor import run_spark_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters to be changed\n",
    "partitionsize = 200000\n",
    "# parameters to be changed\n",
    "thread_workers = 4\n",
    "# parameters to be changed\n",
    "available_laurelin_version = [(\"edu.vanderbilt.accre:laurelin:1.0.0\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "fileset = {\n",
    "    'test': { 'files': ['root://eosuser//eos/user/o/oshadura/coffea/nano_lgray.root'],\n",
    "             'treename': 'Events'\n",
    "            }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def spark_session_startup(laurelin_version):\n",
    "    spark_config = pyspark.sql.SparkSession.builder \\\n",
    "        .appName('spark-executor-test-%s' % guid()) \\\n",
    "        .master('local[*]') \\\n",
    "        .config('spark.driver.memory', '4g') \\\n",
    "        .config('spark.executor.memory', '6g') \\\n",
    "        .config('spark.sql.execution.arrow.enabled','true') \\\n",
    "        .config('spark.sql.execution.arrow.maxRecordsPerBatch', partitionsize) \\\n",
    "        .config('spark.kubernetes.container.image.pullPolicy', 'true') \\\n",
    "        .config('spark.kubernetes.container.image', 'gitlab-registry.cern.ch/db/spark-service/docker-registry/swan:laurelin') \\\n",
    "        .config('spark.kubernetes.memoryOverheadFactor', '0.1')\n",
    "        \n",
    "    spark_session = _spark_initialize(config=spark_config,\n",
    "                                      log_level='WARN', \n",
    "                                      spark_progress=False,\n",
    "                                      laurelin_version=laurelin_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def laurelin_read_loading(laurelin_version, file):\n",
    "    spark_config = pyspark.sql.SparkSession.builder \\\n",
    "        .appName('spark-executor-test-%s' % guid()) \\\n",
    "        .master('local[*]') \\\n",
    "        .config('spark.driver.memory', '4g') \\\n",
    "        .config('spark.executor.memory', '6g') \\\n",
    "        .config('spark.sql.execution.arrow.enabled','true') \\\n",
    "        .config('spark.sql.execution.arrow.maxRecordsPerBatch', partitionsize)\\\n",
    "        .config('spark.kubernetes.container.image.pullPolicy', 'true')\\\n",
    "        .config('spark.kubernetes.container.image', 'gitlab-registry.cern.ch/db/spark-service/docker-registry/swan:laurelin')\\\n",
    "        .config('spark.kubernetes.memoryOverheadFactor', '0.1')     \n",
    "    spark_session = _spark_initialize(config=spark_config,\n",
    "                                      log_level='WARN', \n",
    "                                      spark_progress=False,\n",
    "                                      laurelin_version=laurelin_version)\n",
    "    df = spark_session.read.format('edu.vanderbilt.accre.laurelin.Root') \\\n",
    "            .option(\"tree\", \"Events\") \\\n",
    "            .load(file['test'])\n",
    "    df.printSchema()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def laurelin_read_select(laurelin_version, file):\n",
    "    spark_config = pyspark.sql.SparkSession.builder \\\n",
    "        .appName('spark-executor-test-%s' % guid()) \\\n",
    "        .master('local[*]') \\\n",
    "        .config('spark.driver.memory', '4g') \\\n",
    "        .config('spark.executor.memory', '6g') \\\n",
    "        .config('spark.sql.execution.arrow.enabled','true') \\\n",
    "        .config('spark.sql.execution.arrow.maxRecordsPerBatch', partitionsize)\\\n",
    "        .config('spark.kubernetes.container.image.pullPolicy', 'true')\\\n",
    "        .config('spark.kubernetes.container.image', 'gitlab-registry.cern.ch/db/spark-service/docker-registry/swan:laurelin')\\\n",
    "        .config('spark.kubernetes.memoryOverheadFactor', '0.1')        \n",
    "    spark_session = _spark_initialize(config=spark_config, log_level='WARN', \n",
    "                          spark_progress=False, laurelin_version='1.0.1-SNAPSHOT')\n",
    "    return spark_session\n",
    "    df = laurelin_read_loading(laurelin_version, file)\n",
    "    df_final = df.select(*['nMuon','Muon_pt','Muon_eta','Muon_phi','Muon_mass'])\n",
    "    df_final.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def laurelin_read_show(laurelin_version, file):\n",
    "    spark_config = pyspark.sql.SparkSession.builder \\\n",
    "        .appName('spark-executor-test-%s' % guid()) \\\n",
    "        .master('local[*]') \\\n",
    "        .config('spark.driver.memory', '4g') \\\n",
    "        .config('spark.executor.memory', '6g') \\\n",
    "        .config('spark.sql.execution.arrow.enabled','true') \\\n",
    "        .config('spark.sql.execution.arrow.maxRecordsPerBatch', partitionsize)\\\n",
    "        .config('spark.kubernetes.container.image.pullPolicy', 'true')\\\n",
    "        .config('spark.kubernetes.container.image', 'gitlab-registry.cern.ch/db/spark-service/docker-registry/swan:laurelin')\\\n",
    "        .config('spark.kubernetes.memoryOverheadFactor', '0.1')      \n",
    "    spark_session = _spark_initialize(config=spark_config,\n",
    "                                      log_level='WARN', \n",
    "                                      spark_progress=False,\n",
    "                                      laurelin_version=laurelin_version)\n",
    "\n",
    "    df = laurelin_read_loading(laurelin_version, file)\n",
    "    df_final = df.withColumn('dataset', fn.lit('test'))\n",
    "    df_final.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def laurelin_simple_test(laurelin_version, file):\n",
    "    spark_config = pyspark.sql.SparkSession.builder \\\n",
    "        .appName('spark-executor-test-%s' % guid()) \\\n",
    "        .master('local[*]') \\\n",
    "        .config('spark.driver.memory', '4g') \\\n",
    "        .config('spark.executor.memory', '6g') \\\n",
    "        .config('spark.sql.execution.arrow.enabled','true') \\\n",
    "        .config('spark.sql.execution.arrow.maxRecordsPerBatch', partitionsize)\\\n",
    "        .config('spark.kubernetes.container.image.pullPolicy', 'true')\\\n",
    "        .config('spark.kubernetes.container.image', 'gitlab-registry.cern.ch/db/spark-service/docker-registry/swan:laurelin')\\\n",
    "        .config('spark.kubernetes.memoryOverheadFactor', '0.1')\n",
    "        \n",
    "    spark_session = _spark_initialize(config=spark_config,\n",
    "                                      log_level='WARN', \n",
    "                                      spark_progress=False,\n",
    "                                      laurelin_version=laurelin_version)\n",
    "    df = laurelin_read_loading(laurelin_version, file)\n",
    "    env = Environment(loader=PackageLoader('coffea.processor','templates'),autoescape=select_autoescape(['py']))\n",
    "    columns = ['nMuon','Muon_pt','Muon_eta','Muon_phi','Muon_mass']\n",
    "    cols_w_ds = ['dataset','nMuon','Muon_pt','Muon_eta','Muon_phi','Muon_mass']\n",
    "    processor_instance = NanoTestProcessor(columns=columns)\n",
    "    tmpl = env.get_template('spark.py.tmpl')\n",
    "    render = tmpl.render(cols=columns)\n",
    "    exec(render)\n",
    "    histdf = df.select(coffea_udf(*cols_w_ds).alias('histos'))\n",
    "    pds = histdf.toPandas()\n",
    "    print(pds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'PYSPARK_COFFEABENCH' in os.environ:\n",
    "    @pytest.mark.benchmark(group=\"laurelin-simple-startup\")\n",
    "    def test_spark_session_startup(benchmark):\n",
    "        benchmark(spark_session_startup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'PYSPARK_COFFEABENCH' in os.environ:\n",
    "    @pytest.mark.benchmark(group=\"laurelin-simple-func\")\n",
    "    @pytest.mark.parametrize(\"laurelin_version\", available_laurelin_version)\n",
    "    @pytest.mark.parametrize(\"root_file\", fileset)\n",
    "    def test_laurelin_read_loading(benchmark, laurelin_version):\n",
    "        benchmark(laurelin_read_loading, laurelin_version, fileset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'PYSPARK_COFFEABENCH' in os.environ:\n",
    "    @pytest.mark.benchmark(group=\"laurelin-simple-func\")\n",
    "    @pytest.mark.parametrize(\"laurelin_version\", available_laurelin_version)\n",
    "    @pytest.mark.parametrize(\"root_file\", fileset)\n",
    "    def test_laurelin_read_select(benchmark, laurelin_version):\n",
    "        benchmark(laurelin_read_select, laurelin_version, fileset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'PYSPARK_COFFEABENCH' in os.environ:\n",
    "    @pytest.mark.benchmark(group=\"laurelin-simple-func\")\n",
    "    @pytest.mark.parametrize(\"laurelin_version\", available_laurelin_version)\n",
    "    @pytest.mark.parametrize(\"root_file\", fileset)\n",
    "    def test_laurelin_read_show(benchmark, laurelin_version):\n",
    "        benchmark(laurelin_read_show, laurelin_version, fileset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'PYSPARK_COFFEABENCH' in os.environ:\n",
    "    @pytest.mark.benchmark(group=\"laurelin-simple-func\")\n",
    "    @pytest.mark.parametrize(\"laurelin_version\", available_laurelin_version)\n",
    "    @pytest.mark.parametrize(\"root_file\", fileset)\n",
    "    def test_laurelin_simple_test(benchmark, laurelin_version):\n",
    "        benchmark(laurelin_simple_test, laurelin_version, fileset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(__builtins__,'__IPYTHON__'):\n",
    "    ipytest.run('-qq')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
