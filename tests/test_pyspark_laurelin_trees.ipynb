{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell if you do not have coffea installed (e.g. on SWAN with LCG 96Python3 stack)\n",
    "# (for .py version -> next line should be commented since they are converted to ipybn via jupytext)\n",
    "!pip install --user --upgrade coffea\n",
    "# Preparation for testing\n",
    "!pip install --user --upgrade ipytest\n",
    "!pip install --user --upgrade pytest-benchmark\n",
    "!pip install --user --upgrade pytest-csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.jars.packages doesnt work with Spark 2.4 with kubernetes\n",
    "!wget -N https://repo1.maven.org/maven2/edu/vanderbilt/accre/laurelin/1.0.0/laurelin-1.0.0.jar\n",
    "!wget -N https://repo1.maven.org/maven2/org/apache/logging/log4j/log4j-api/2.11.2/log4j-api-2.11.2.jar\n",
    "!wget -N https://repo1.maven.org/maven2/org/apache/logging/log4j/log4j-core/2.11.2/log4j-core-2.11.2.jar\n",
    "!wget -N https://repo1.maven.org/maven2/org/lz4/lz4-java/1.5.1/lz4-java-1.5.1.jar\n",
    "!wget -N https://repo1.maven.org/maven2/org/tukaani/xz/1.2/xz-1.2.jar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment this if you want to test Dask:\n",
    "%env DASK_COFFEABENCH=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment this if you want to test Spark:\n",
    "%env PYSPARK_COFFEABENCH=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment this if you want to test uproot:\n",
    "%env UPROOT_COFFEABENCH=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(__builtins__,'__IPYTHON__'):\n",
    "    import os\n",
    "    import ipytest\n",
    "    ipytest.config(rewrite_asserts=True, magics=True)\n",
    "    __file__ = 'test_pyspark_laurelin_trees.ipynb'\n",
    "    # Run this cell before establishing spark connection <<<<< IMPORTANT\n",
    "    os.environ['PYTHONPATH'] = os.environ['PYTHONPATH'] + ':' + '/usr/local/lib/python3.6/site-packages'\n",
    "    os.environ['PATH'] = os.environ['PATH'] + ':' + '/eos/user/o/oshadura/.local/bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import os\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if 'PYSPARK_COFFEABENCH' in os.environ:\n",
    "    import pyspark.sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in glob.glob(\"samples/*.root\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "available_laurelin_version = [(\"edu.vanderbilt.accre:laurelin:1.0.0\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class RegexSwitch(object):\n",
    "  def __init__(self):\n",
    "    self.last_match = None\n",
    "  def match(self,pattern,text):\n",
    "    self.last_match = re.match(pattern,text)\n",
    "    return self.last_match\n",
    "  def search(self,pattern,text):\n",
    "    self.last_match = re.search(pattern,text)\n",
    "    return self.last_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def laurelin_read_simple_flat_tree(laurelin_version, file):\n",
    "    gre = RegexSwitch()\n",
    "    spark = pyspark.sql.SparkSession.builder \\\n",
    "        .master(\"local[1]\") \\\n",
    "        .config('spark.jars.packages', laurelin_version) \\\n",
    "        .getOrCreate()\n",
    "    sc = spark.sparkContext\n",
    "    if gre.match(r'sample',file):\n",
    "        treename = \"sample\"\n",
    "    elif gre.match(r'HZZ-objects',file) or gre.match(r'Zmumu',file):\n",
    "        treename = \"events\"\n",
    "    else:\n",
    "        treename = \"tree\"\n",
    "    df = spark.read.format('edu.vanderbilt.accre.laurelin.Root') \\\n",
    "            .option(\"tree\", treename) \\\n",
    "            .load(files)\n",
    "    df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'PYSPARK_COFFEABENCH' in os.environ:\n",
    "    @pytest.mark.benchmark(group=\"laurelin-simple-root-tree\")\n",
    "    @pytest.mark.parametrize(\"laurelin_version\", available_laurelin_version)\n",
    "    @pytest.mark.parametrize(\"root_file\", files)\n",
    "    def test_laurelin_read_simple_flat_tree(benchmark, laurelin_version, root_file):\n",
    "        benchmark(laurelin_read_simple_flat_tree, laurelin_version, root_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(__builtins__,'__IPYTHON__'):\n",
    "    ipytest.run('-qq')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
